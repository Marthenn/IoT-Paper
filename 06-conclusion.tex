\section{Conclusion}
We have presented a modular, low-cost SAR robot framework combining TinyML audio detection with RSSI ranging. The platform’s hardware (ESP32 microcontrollers and simple sensors) and software (embedded neural network) are inherently cheap and power-efficient, aligning with the “low cost, simplicity, and commonly-available elements” desirable in SAR systems. 

The TinyML speech classifier proved highly effective, achieving ~97.8\% human-voice detection accuracy on the embedded device. This result is in line with recent work on microcontroller-based speech recognition, confirming that compact neural models can run reliably on battery-powered SAR robots. The RSSI-based localization method successfully provided approximate indoor positioning (mean error $\approx$0.5 m) without additional hardware. In practice, however, its accuracy is coarse and environment-dependent. As reported in prior studies, RSSI localization can suffer error variations due to walls, multipath, and interference. Our experiments reflected this: while the average error was sub-meter in open areas, it increased in cluttered or reflective spaces. Thus, the RSSI approach proved useful for rough triangulation but has clear limitations in precision.

Overall, our multi-modal SAR robot demonstrates that embedding intelligence in inexpensive hardware is viable for rescue scenarios. The combination of voice-based victim detection and wireless localization adds capability beyond basic tele-operation. In future deployments, such a system could be used to listen for survivors and guide responders even in NLOS conditions. In sum, the results show that a minimalist, sensor-rich design can offer real-world value, enabling a cost-effective SAR robot.